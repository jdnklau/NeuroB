package neurob.latex.hyperparametersearch;

import neurob.latex.interfaces.TeXable;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.NoSuchElementException;
import java.util.stream.Collectors;
import java.util.stream.IntStream;
import java.util.stream.Stream;

/**
 * Searches a specified random search directory and collects the n best results.
 * It specifically is for the results generated by {@link neurob.training.HyperParameterSearch}
 * class.
 * <p>
 *     This is done by looking into each epochs.csv generated and comparing the best test results.
 * </p>
 *
 * @author Jannik Dunkelau
 */
public class SearchResultCrawler implements TeXable {
	private final int maxResults;
	private List<SearchResultEntry> results;

	private static final Logger log = LoggerFactory.getLogger(SearchResultCrawler.class);

	/**
	 * @param n The n best results will be collected
	 */
	public SearchResultCrawler(int n) {
		maxResults = n;
		results = new ArrayList<>();
	}

	public List<SearchResultEntry> getResults(){
		return results;
	}

	/**
	 * Crawls through the specified directory and gathers the n best results.
	 *
	 * @param directory Directory to be searched for, initially generated by
	 *                  {@link neurob.training.HyperParameterSearch}
	 * @return The number of found results m, with m&le;n
	 */
	public int crawl(Path directory) {
		try (Stream<Path> stream = Files.walk(directory)) {
			stream
					.filter(path -> path.toString().endsWith("epochs.csv"))
					.forEach(this::checkResults);
		} catch (IOException e) {
			e.printStackTrace();
		}

		return results.size();
	}

	private void checkResults(Path csv) {
		// get index of model
		int idx = Integer.parseInt(csv.getParent().getFileName().toString());
		// get best performance from csv
		double performance;
		try(Stream<String> lines = Files.lines(csv)){
			List<Double> performances = lines
					.skip(1)
					.map(this::getTestPerformanceFromLine)
					.collect(Collectors.toList());

			Collections.sort(performances);
			performance = performances.get(performances.size()-1); // best performance is last one
		} catch (IOException | NoSuchElementException e) {
			log.warn("Could not get performance for model {} over epoch csv {}",
					idx, csv, e);
			performance = 0;
		}

		insertResultOrdered(idx,performance,csv);
	}

	private void insertResultOrdered(int idx, double performance, Path source) {
		SearchResultEntry res = new SearchResultEntry(idx, performance, source);

		// if first result to add, nothing more to do
		if(results.isEmpty()){
			results.add(res);
			return;
		}

		// if already results present, binary search to add at right place
		int k = results.size()/2; // index to look for
		int kOld = results.size(); // previous looked at index
		boolean isInserted = false;
		while(!isInserted & k<maxResults){
			SearchResultEntry compare = results.get(k);
			int kTemp = k; // save current k
			int offset=0; // only needed for insertion at end
			// found better result
			if(res.isGreaterThan(compare)){
				int reference = (k<kOld) ? 0 : kOld;
				k = (k-reference)/2; // find your place, little result
			}
			else { // performance is worse
				int reference = (k>kOld) ? results.size() : kOld;
				k += (reference-k)/2;
				offset = 1; // order it at insertion one place behind
			}
			kOld = kTemp;

			// if comparing with previous result, we found our place
			if(k==kOld && k<maxResults){
				results.add(k+offset, res);
				isInserted = true;
			}
		}

		// check that the list is not longer than maxResults
		while(results.size() > maxResults){
			results.remove(results.size()-1); // remove last element
		}
	}

	private Double getTestPerformanceFromLine(String line) {
		// split csv line into individual entries
		String[] entries = line.split(",");
		// last entry is the final test performance
		return Double.parseDouble(entries[entries.length-1]);
	}

	@Override
	public String getTeX() {
		String tex =
				"\\begin{tikzpicture}[scale=0.85, transform shape]\n" +
				"    \\begin{axis}\n" +
				"        [\n" +
				"            ymin = 0.4,\n" +
				"            ymax = 1,\n" +
				"            legend style={at={(0.95,0.05)}, anchor=south east, font=\\small},\n" +
				"            ylabel={$F_1$-Score},\n" +
				"            xlabel={$\\#$ Number of epochs}\n" +
				"        ]\n";

		tex+= getTeXPlots();

		tex +=
				"    \\end{axis}\n" +
				"\\end{tikzpicture}";
		return tex;
	}

	private String getTeXPlots(){
		String plots = "";

		for(SearchResultEntry res : results){
			// load csv lines
			Path csv = res.getSource();
			try(Stream<String> lines = Files.lines(csv)){
				// set up coordinates
				String coordinateList =
					lines.skip(1).map(this::mapCSVLineToCoordinates)
						.collect(Collectors.joining("\n            "));
				// set up plot
				plots += "        % "+csv+"\n";
				plots += "        \\addplot coordinates {\n            ";
				plots += coordinateList;
				plots += "\n        };\n";
			} catch (IOException e) {
				log.warn("Could not load lines from {}", csv, e);
			}
		}

		// add legend
		plots += "%        \\legend{";
		plots += IntStream.rangeClosed(1,results.size()).boxed()
				.map(integer -> Integer.toString(integer)).collect(Collectors.joining(","));
		plots += "}\n";

		return plots;
	}

	private String mapCSVLineToCoordinates(String csvLine) {
		// split csv line and get epoch (first elem) and test performance (last elem)
		String[] parts = csvLine.split(",");
		String epoch = parts[0];
		String performance = parts[parts.length-1];

		return "("+epoch+","+performance+")";
	}
}

