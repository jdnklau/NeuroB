# To Do List
- random predicate generator
    - check whether something like this already exists for B/EventB
    - tool to insert formal grammar and generate an amount of correct syntax snippets
- find and read papers
    - rnn for code/text classification
- model handling
    - iterate if NeuroBNet class is still necessary
        - feed complete models to NeuroB class and gain one abstraction layer less?
            - make NeuroB full utility class
            - give model, feature generator and label generator as parameters
            - **label generator only relevant if model needs to be trained**

        - still use NeuroBNet as model independent wrapper class if maybe the backend will be switched to TensorFlow in the future?
    - have list of preprocessing utilities that is managed by responsible class
- training
    - logging
    - calculate training error thus far
        - after X iterations rather than just after each epoch
    - save files to disk by default
    - more generic handling of data preprocessing if possible
- training set generation
    - model check machines
        - generate 100 states per solver
        - give credit to fastest one
    - optimise
    - ~~add formulae wrapper, allowing for easier manipulation of them~~
        - ~~idea is to have a FormulaCollection object (or similar), e.g. called f, that allows wraps internally an array list of strings/ASTs~~
        - ~~one may then call f.manipulationOfAST1().manipulationOfAST2()~~
        - ~~decide whether it should simply manipulate the already present formulae or add the manipulated results to them (aka augment present data vs. augment copy of present data and keep both)~~
        - ~~maybe just allow methods and other classes to operate on such an element, but offer not much functionality on its own?~~
            - to many wrapper abstractions
    - data augmentation for larger training sets
        - throw in some equivalences in the extended guard formulae, to step up hardness of decidability
        - invariants & guards1 & ~guards2
        - ~~drop randomly (30% chance?) basic nodes in ast~~
        - access/generate proof obligations
    - more distinct support for convolutional models
- training set analysis should be deeper
    - offer fancy stuff like PCA
    - code portfolios
        - ~~translating image directory back to csv~~
        - zip images to big binary rather than csv or directory hierarchy
            - this means hand crafted data pipeline
            - benefits:
                - images as binary objects rather than their feature string representation
                - still regression is part of the deal as no directory hierarchy is necessary but only the data pack
    - analyse regression
        - get min and max value for each label generated
        - get mean, std dev, median
        - basically some box plot values
- update cli
    - instead of setting neural net identifiers as arguments, allow for construction by giving label generator and feature generator
        - this eases up implementation of new generators, as not each possible combination would be in need of a name but only the new generator
- update java doc
