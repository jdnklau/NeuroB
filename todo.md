# To Do List
- **Redo training step**
  - training set generation should automatically split data into train and test data
  - separate files
  - issues with current implementation:
    - batches are in each epoch shuffeled randomly (same seed)
    - then they are randomly split into train and test data (**no seed**)
    - as this happens in each epoch, the epochs run on slightly different data each
    - test step happens after each batch in each epoch -> bad
    - instead should run after complete training step on a clearly/cleanly separated test set
    - results so far are questionable
- reorganise the structure of NeuroB Nets to make them more Plug and Play
- overhaul logging system
  - maybe switch to logging library
  - stop using NeuroB-Trainingsetgenerator as only name for logfiles
    - at least use only NeuroB
    - ideally have different names for different tasks
- trainingset generation and analysisn of the set should inspect the labelings differently
  - perhaps a list of how often an individual labeling was used instead of only checking if the outputs are all the same or not
  - allow a deeper analysis
    - e.g. list predicates with the same features but different labelings
- Test cases for training data generation
  - small example files should suffice
  - think about solution to compare Code Portfolios
- change handling in Cli of neural nets
  - allow to give custom seed(s) for RNG
  - training multiple nets with different seeds should create the next net after the previous one has finished training
